<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="description" content="ForceMimic" />
    <meta
      name="keywords"
      content="ForceMimic, ForceCapture, HybridIL, Robotics, Robot Learning, Imitation Learning, Hybrid Force-Position Control, Vegetable Peeling"
    />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>ForceMimic</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PMWMSYT7XX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-PMWMSYT7XX');
    </script>

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />
    <link rel="icon" href="./static/images/favicon.png" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
  </head>

  <body>
    <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
      <div class="navbar-brand">
        <a
          role="button"
          class="navbar-burger"
          aria-label="menu"
          aria-expanded="false"
        >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>
      <div class="navbar-menu">
        <div class="navbar-start" style="flex-grow: 1; justify-content: center">
          <a class="navbar-item" href="https://forcemimic.github.io/">
            <span class="icon">
              <i class="fas fa-home"></i>
            </span>
          </a>

          <div class="navbar-item has-dropdown is-hoverable">
            <a class="navbar-link"> Related Work </a>
            <div class="navbar-dropdown">
              <a class="navbar-item" href="https://xxx"> xxx </a>
            </div>
          </div>
        </div>
      </div>
    </nav> -->

    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                <span class="highlight">ðŸ¦¾ ForceMimic</span>
              </h1>
              <h1 class="title is-2 publication-title">
                <span>Force-Centric Imitation Learning with Force-Motion Capture System for Contact-Rich Manipulation</span>
              </h1>

              <!-- <h4 class="title is-4 conference"><a href="https://2025.ieee-icra.org/" class="conference">IEEE International Conference on Robotics and Automation (<span class="grad_text">ICRA</span>) 2025</a></h4> -->

              <!-- <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="mailto:sjtu-wenhai@sjtu.edu.cn">Wenhai Liu</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="https://dadadadawjb.github.io/">Junbo Wang</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="mailto:sommerfeld@sjtu.edu.cn">Yiming Wang</a
                  ><sup>*</sup>,
                </span>
                <span class="author-block">
                  <a href="mailto:wangweiming@sjtu.edu.cn">Weiming Wang</a
                  ><sup></sup>,
                </span>
                <span class="author-block">
                  <a href="https://www.mvig.org/">Cewu Lu</a
                    ><sup>&dagger;</sup>,
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">Shanghai Jiao Tong University</span>
              </div>

              <div class="is-size-6 publication-authors">
                (<sup>*</sup
                ><span class="author-block"> Equal Contribution</span
                >, <sup>&dagger;</sup
                ><span class="author-block"> Corresponding Author</span>)
              </div> -->

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a
                      href=""
                      class="external-link button is-normal is-rounded is-orange"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                      href="https://youtu.be/jrUJ2Ne2vhY"
                      class="external-link button is-normal is-rounded is-orange"
                    >
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a
                    href=""
                    class="external-link button is-normal is-rounded is-orange"
                    >
                    <span class="icon">
                      <i class="fa fa-wrench"></i>
                    </span>
                    <span>Hardware (coming soon)</span>
                  </a>
                </span>
                <span class="link-block">
                  <a
                    href=""
                    class="external-link button is-normal is-rounded is-orange"
                  >
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>
                </div>
              </div>

              <img
                src="./static/images/teaser.png"
                alt="Teaser"
                style="width: 100%">
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                In most contact-rich manipulation tasks,
                humans apply time-varying forces to the target object,
                compensating for inaccuracies in the vision-guided hand trajectory.
                However, current robot learning algorithms primarily focus on trajectory-based policy,
                with limited attention given to learning force-related skills.
                To address this limitation, we introduce <b class="highlight">ForceMimic</b>,
                a force-centric robot learning system, providing a natural,
                force-aware and robot-free robotic demonstration collection system,
                along with a hybrid force-motion imitation learning algorithm for robust contact-rich manipulation.
                Using the proposed <b class="highlight">ForceCapture</b> system,
                an operator can peel a zucchini in 5 minutes,
                while force-feedback teleoperation takes over 13 minutes and struggles with task completion.
                With the collected data, we propose <b class="highlight">HybridIL</b> to train a force-centric imitation learning model,
                equipped with hybrid force-position control primitive to fit the predicted wrench-position parameters during robot execution.
                Experiments demonstrate that our approach enables the model to learn a more robust policy under the contact-rich task of vegetable peeling,
                increasing the success rates by 54.5% relatively compared to state-of-the-art pure-vision-based imitation learning.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe
                src="https://www.youtube.com/embed/jrUJ2Ne2vhY?si=vrPJVgsGBheA6c9p?rel=0&amp;showinfo=0"
                title="YouTube video player"
                frameborder="0"
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
                allowfullscreen
              ></iframe>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3 highlight" id="ForceCapture">ForceCapture</h2>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="column content has-text-justified">
              <ul>
                <li><b>Objectives</b></li>
                <ul>
                  <li>Scalability</li>
                  <li>On-site force realism</li>
                  <li>Ergonomic comfort</li>
                </ul>
                <li><b>Mechanisms</b></li>
                <ul>
                  <li>Ratchet locking</li>
                  <li>Gravity compensation</li>
                </ul>
              </ul>
              <br />

              <p>
                Two versions of ForceCapture are designed,
                one with a fixed tool and the other with an adaptive gripper.
                At its core, both designs share the feature of a six-axis force sensor placed between the end-effector and the user's gripping handle,
                which can be used to capture the effector-environment interaction forces.
              </p>
              <p>
                ForceCapture is quite straightforward to manufacture,
                with the main body fully produced using 3D printing.
                The total cost of the printed parts and encoder is approximately $50.
                The weight of the device equipped with the gripper is only 0.8kg,
                of which the force sensor weighs 0.5kg, and our accessories weigh only 0.3kg,
                which is even lighter than a can of cola.
                And its center of mass is positioned above the handle,
                conforms to the natural force application habits of the human hand.
              </p>
              <p>
                Except for the effector-environment interaction forces,
                forces exerted by human hands during opening and closing,
                and the gravity of the effector are also captured.
                A ratchet is inserted to isolate human hand forces by unidirectional locking if closed,
                and least-squares estimation of the effector's center of mass and weight is used to compensate for the self-gravity before collecting data.
              </p>

              <div class="content has-text-centered">
                <video controls autoplay muted loop style="width: 49%">
                  <source
                    src="./static/videos/collection_clip_compressed.mp4"
                    type="video/mp4"
                  />
                  Your browser does not support the video tag.
                </video>
                <video controls autoplay muted loop style="width: 49%">
                  <source
                    src="./static/videos/sim_collection_zero_clip_compressed.mp4"
                    type="video/mp4"
                  />
                  Your browser does not support the video tag.
                </video>
              </div>
            </div>
          </div>

          <div class="column has-text-centered">
            <div class="content">
              <img
                src="./static/images/hardware.png"
                alt="Hardware"
                style="width: 100%"
              />
            </div>

            <div class="content">
              <video controls autoplay muted loop style="width: 75%">
                <source
                  src="./static/videos/show_device_clip_compressed.mp4"
                  type="video/mp4"
                />
                Your browser does not support the video tag.
              </video>
            </div>
          </div>
        </div>
      </div>

      <!-- <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <p>
              Hello World!
            </p>
          </div>
        </div>
      </div> -->
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3 highlight" id="HybridIL">HybridIL</h2>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <img
                src="./static/images/pipeline.png"
                alt="Pipeline"
                style="width: 100%"
              />

            <p>
              We first transfer the collected robot-free data to (pseudo-)robot data, migrating the domain gap.
              The captured wrench is compensated to account for self-gravity effects.
              The pose recorded by SLAM camera is transformed as the robot TCP pose.
              And RGB-D observation images are backprojected into point cloud and filtered out unrelated points.
              Leveraging this data, a diffusion-based policy is learned,
              with both pose and wrench trajectory predicted,
              conditioned on the encoded point cloud features, history pose and diffusion timestep embeddings.
              According to the predicted force value,
              either IK joint position primitive or hybrid force-position primitive is selected,
              and fits the output force-position parameters to conduct execution actions.
            </p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div class="column content has-text-justified">
              <ul>
                <li><b>Using orthogonal hybrid force-postion controller to fit predicted wrench-position</b></li>
                <ul>
                  <li>Active on consecutive force threshold exceedance</li>
                  <li>Determine motion direction</li>
                  <li>Orthogonalize force-postion</li>
                  <li>Press opposite initially</li>
                </ul>
              </ul>
              <br />

              <p>
                Realized by Flexiv RDK of hybrid force-position control primitive.
              </p>
            </div>
          </div>

          <div class="column has-text-centered">
            <div class="content">
              <img
                src="./static/images/controller.png"
                alt="Controller"
                style="width: 100%"
              />
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Data Collection Efficiency</h2>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <p>
              We conduct a case study of data collection by peeling a zucchini using a single-arm.
              The procedure involved picking up the peeler, peeling the zucchini on a stand, placing the peeler down,
              then grasping the zucchini to adjust its orientation for peeling until the entire vegetable was peeled.
              We use the gripper version of <a href="#ForceCapture">ForceCapture</a>,
              and the teleoperation setup follows the configuration in <a href="https://rh20t.github.io/">RH20T</a>.
            </p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content has-text-centered">
            <video controls autoplay muted loop style="width: 50%">
              <source
                src="./static/videos/collection2_clip_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Demo clip by ForceCapture</p>
          </div>

          <div class="column content">
            <img
              src="./static/images/efficiency_result.png"
              alt="Quantitative Results"
              style="width: 100%"
            />
            <br />
            <p align="center">Efficiency comparison</p>
          </div>

          <div class="column content has-text-centered">
            <video controls autoplay muted loop style="width: 50%">
              <source
                src="./static/videos/teleoperation_clip_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Demo clip by Teleoperation</p>
          </div>
        </div>

        <p>
          Not only the collection time of ForceCapture is very close to humans,
          but also it takes nearly no additional training time and nearly no operational errors.
        </p>
      </div>
    </section>

    <section class="section">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Robotic Peeling Experiments</h2>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <p>
              We use the fixed-tool version of ForceCapture to collect data,
              with total 15 zucchinis, collecting 438 peeling skill segments,
              resulting in a total of 30,199 action sequences.
              Leveraging the collected data, 
              we train the HybridIL model and the baseline methods, all by 500 epochs.
            </p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <video controls autoplay muted loop style="width: 100%">
              <source
                src="./static/videos/dataset_replay_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Dataset replay by ForceCapture</p>
          </div>

          <div class="column content">
            <video controls autoplay muted loop style="width: 100%">
              <source
                src="./static/videos/dataset_aug_replay_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Pose-augmented dataset replay by ForceCapture</p>
          </div>

          <div class="column content">
            <video controls autoplay muted loop style="width: 100%">
              <source
                src="./static/videos/dataset_test_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Rollout on validation dataset by HybridIL</p>
          </div>

          <div class="column content">
            <video controls autoplay muted loop style="width: 100%">
              <source
                src="./static/videos/hybridil_seq_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Rollout on real robot by HybridIL</p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <li><b>Raw DP</b> used raw visual perception and robot pose as inputs, outputting the end- effector pose sequence based on diffusion policy.</li>
            <li><b>Force DP</b> incorporated visual perception, robot pose, and robot force sensing as inputs, also outputting the end-effector pose sequence.</li>
            <li><b>Force+Hybrid DP</b> used visual perception, robot pose, and robot force sensing as inputs, but output both pose and wrench sequences</li>
            <p>
              For baselines that output wrench-position parameters, hybrid force-position control primitives were employed to match and switch between control modes.
              Raw DP and HybridIL were tested for 20 peeling actions,
              while Force DP and Force+Hybrid DP were tested for 10 peeling actions.
            </p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <table class="table is-striped is-fullwidth">
              <thead>
                <tr>
                  <th rowspan="2">Method</th>
                  <th colspan="2">Success rate (%)</th>
                </tr>
                <tr>
                  <td>motion correct</td>
                  <td>peel length > 10cm</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Raw DP</td>
                  <td>80</td>
                  <td>55</td>
                </tr>
                <tr>
                  <td>Force DP</td>
                  <td>60</td>
                  <td>10</td>
                </tr>
                <tr>
                  <td>Force+Hybrid DP</td>
                  <td>80</td>
                  <td>20</td>
                </tr>
                <tr>
                  <td><b>HybridIL (proposed)</b></td>
                  <td><b>100</b></td>
                  <td><b>85</b></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <img
              src="./static/images/rawdp_skin_result.png"
              alt="Raw DP"
              style="width: 100%"
            />
            <br />
            <p align="center">Peeled skins by Raw DP</p>
          </div>

          <div class="column content">
            <img
              src="./static/images/ablation_skin_result.png"
              alt="Ablation"
              style="width: 100%"
            />
            <br />
            <p align="center">Peeled skins by Force DP (left) and Force+Hybrid DP (right)</p>
          </div>

          <div class="column content">
            <img
              src="./static/images/hybridil_skin_result.png"
              alt="HybridIL"
              style="width: 100%"
            />
            <br />
            <p align="center">Peeled skins by HybridIL</p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <video controls autoplay muted loop style="width: 100%">
              <source
                src="./static/videos/cut_experiments_compressed.mp4"
                type="video/mp4"
              />
              Your browser does not support the video tag.
            </video>
            <br />
            <p align="center">Rollouts on real robot by Raw DP and HybridIL</p>
          </div>
        </div>
      </div>

      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered has-text-justified">
          <div class="column content">
            <img
              src="./static/images/gt_f_curve.png"
              alt="GT Force Curve"
              style="width: 100%"
            />
            <br />
            <p align="center">Force curve during data collection</p>
          </div>

          <div class="column content">
            <img
              src="./static/images/position_f_curve.png"
              alt="Position Force Curve"
              style="width: 100%"
            />
            <br />
            <p align="center">Force curve during rollout of Raw DP</p>
          </div>

          <div class="column content">
            <img
              src="./static/images/hybrid_f_curve.png"
              alt="Hybrid Force Curve"
              style="width: 100%"
            />
            <br />
            <p align="center">Force curve during rollout of HybridIL</p>
          </div>
        </div>

        <p>
          Force DP and Force+Hybrid DP performed poorly. 
          The mismatch between input forces and the force distribution in the dataset made it difficult for the models to predict the correct actions.
          Not only the success rates of HybridIL are higher than the baselines,
          but also the peeled skins of HybridIL are longer and smoother,
          and the interaction forces during execution are more similar to the collected data by human operators.
        </p>
      </div>
    </section>

    <!-- <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="columns is-centered has-text-centered">
          <h2 class="title">BibTeX</h2>
        </div>
        <p>If you find it helpful, please consider citing our work: </p>
        <pre><code>
</code></pre>
      <p>
        If you have further questions, please feel free to drop an email to
        <a href="mailto:sjtu-wenhai@sjtu.edu.cn">sjtu-wenhai@sjtu.edu.cn</a>,
        <a href="mailto:sjtuwjb3589635689@sjtu.edu.cn">sjtuwjb3589635689@sjtu.edu.cn</a>,
        <a href="mailto:sommerfeld@sjtu.edu.cn">sommerfeld@sjtu.edu.cn</a>.
      </p>
      </div>
    </section> -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >. This page is modified upon
                <a href="https://nerfies.github.io/">Nerfies</a> website (<a
                  href="https://github.com/nerfies/nerfies.github.io"
                  >source</a
                >).
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
